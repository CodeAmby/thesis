{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72315b1f-d7c9-4753-bd5a-fe2c94b2ac30",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Step 3: Combine all tables into a single DataFrame\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_tables:\n\u001b[1;32m---> 23\u001b[0m     combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_tables, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(combined_df\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# Display the first few rows\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pdfplumber\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Fetch the PDF from the URL\n",
    "pdf_url = \"https://budget.finance.go.ug/sites/default/files/Sector%20Spending%20Agency%20Budgets%20and%20Performance/Ministry%20of%20Education%20and%20Sports_3.pdf\"\n",
    "response = requests.get(pdf_url)\n",
    "pdf_file = BytesIO(response.content)\n",
    "\n",
    "# Step 2: Extract tables from the PDF\n",
    "with pdfplumber.open(pdf_file) as pdf:\n",
    "    all_tables = []\n",
    "    for page in pdf.pages:\n",
    "        tables = page.extract_tables()\n",
    "        for table in tables:\n",
    "            if table:  # Ensure the table is not empty\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])  # Skip header row\n",
    "                all_tables.append(df)\n",
    "\n",
    "# Step 3: Combine all tables into a single DataFrame\n",
    "if all_tables:\n",
    "    combined_df = pd.concat(all_tables, ignore_index=True)\n",
    "    print(combined_df.head())  # Display the first few rows\n",
    "else:\n",
    "    print(\"No tables found in the PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e239ec5-e0c0-4abf-a15d-1bbc05c6a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error processing table on page 1, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 2, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 3, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 4, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 5, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 6, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 7, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 8, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 9, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 10, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 11, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 12, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 13, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 14, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 15, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 16, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 17, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 18, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 19, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 20, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 21, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 22, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 23, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 24, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 25, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 26, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 27, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 28, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 29, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 30, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 31, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 32, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 33, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 34, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 35, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 36, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "⚠️ Error processing table on page 37, table 1: module 'pandas.io.parsers' has no attribute 'ParserBase'\n",
      "✅ Combined DataFrame preview:\n",
      "  Total Excluding Arrears 266,506,287 189,107,094 455,613,382  \\\n",
      "0                     NaN         NaN         NaN         NaN   \n",
      "1                     NaN         NaN         NaN         NaN   \n",
      "2                     NaN         NaN         NaN         NaN   \n",
      "3                     NaN         NaN         NaN         NaN   \n",
      "4                     NaN         NaN         NaN         NaN   \n",
      "\n",
      "                            Million Uganda Shillings 2022/23 Draft Estimates  \n",
      "0                                              Total                    None  \n",
      "1            Project 1338 Skills Development Project                  73,750  \n",
      "2    410 International Development Association (IDA)                  73,750  \n",
      "3  Project 1432 OFID Funded Vocational Project Ph...                  73,322  \n",
      "4  403 Arab Bank for Economic Development in Afri...                  73,322  \n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# Step: Extract and clean tables from the loaded PDF\n",
    "all_tables = []\n",
    "\n",
    "with pdfplumber.open(pdf_file) as pdf:\n",
    "    for page_num, page in enumerate(pdf.pages):\n",
    "        tables = page.extract_tables()\n",
    "        for table_num, table in enumerate(tables):\n",
    "            if table:\n",
    "                try:\n",
    "                    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                    \n",
    "                    # Check for duplicate columns\n",
    "                    if not df.columns.is_unique:\n",
    "                        # Auto-rename duplicate columns\n",
    "                        df.columns = pd.io.parsers.ParserBase({'names': df.columns})._maybe_dedup_names(df.columns)\n",
    "                        print(f\"🔄 Renamed duplicate columns on page {page_num+1}, table {table_num+1}\")\n",
    "                    \n",
    "                    all_tables.append(df)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error processing table on page {page_num+1}, table {table_num+1}: {e}\")\n",
    "\n",
    "# Step: Combine all tables into a single DataFrame\n",
    "if all_tables:\n",
    "    combined_df = pd.concat(all_tables, ignore_index=True)\n",
    "    print(\"✅ Combined DataFrame preview:\")\n",
    "    print(combined_df.head())\n",
    "else:\n",
    "    print(\"❌ No usable tables found in the PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea40bbf7-8813-490d-869f-9dbac70b95f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Renamed duplicate columns on page 1, table 1\n",
      "🔄 Renamed duplicate columns on page 2, table 1\n",
      "🔄 Renamed duplicate columns on page 3, table 1\n",
      "🔄 Renamed duplicate columns on page 4, table 1\n",
      "🔄 Renamed duplicate columns on page 5, table 1\n",
      "🔄 Renamed duplicate columns on page 6, table 1\n",
      "🔄 Renamed duplicate columns on page 7, table 1\n",
      "🔄 Renamed duplicate columns on page 8, table 1\n",
      "🔄 Renamed duplicate columns on page 9, table 1\n",
      "🔄 Renamed duplicate columns on page 10, table 1\n",
      "🔄 Renamed duplicate columns on page 11, table 1\n",
      "🔄 Renamed duplicate columns on page 12, table 1\n",
      "🔄 Renamed duplicate columns on page 13, table 1\n",
      "🔄 Renamed duplicate columns on page 14, table 1\n",
      "🔄 Renamed duplicate columns on page 15, table 1\n",
      "🔄 Renamed duplicate columns on page 16, table 1\n",
      "🔄 Renamed duplicate columns on page 17, table 1\n",
      "🔄 Renamed duplicate columns on page 18, table 1\n",
      "🔄 Renamed duplicate columns on page 19, table 1\n",
      "🔄 Renamed duplicate columns on page 20, table 1\n",
      "🔄 Renamed duplicate columns on page 21, table 1\n",
      "🔄 Renamed duplicate columns on page 22, table 1\n",
      "🔄 Renamed duplicate columns on page 23, table 1\n",
      "🔄 Renamed duplicate columns on page 24, table 1\n",
      "🔄 Renamed duplicate columns on page 25, table 1\n",
      "🔄 Renamed duplicate columns on page 26, table 1\n",
      "🔄 Renamed duplicate columns on page 27, table 1\n",
      "🔄 Renamed duplicate columns on page 28, table 1\n",
      "🔄 Renamed duplicate columns on page 29, table 1\n",
      "🔄 Renamed duplicate columns on page 30, table 1\n",
      "🔄 Renamed duplicate columns on page 31, table 1\n",
      "🔄 Renamed duplicate columns on page 32, table 1\n",
      "🔄 Renamed duplicate columns on page 33, table 1\n",
      "🔄 Renamed duplicate columns on page 34, table 1\n",
      "🔄 Renamed duplicate columns on page 35, table 1\n",
      "🔄 Renamed duplicate columns on page 36, table 1\n",
      "🔄 Renamed duplicate columns on page 37, table 1\n",
      "✅ Combined DataFrame preview:\n",
      "                           Thousand Uganda Shillings 2022/23 Draft Estimates  \\\n",
      "0                                                                        GoU   \n",
      "1            Programme: 12 HUMAN CAPITAL DEVELOPMENT                    None   \n",
      "2  01 Career Guidance, Counselling and Placement\\...                 958,851   \n",
      "3                                               None              83,971,847   \n",
      "4                                               None               2,005,244   \n",
      "\n",
      "            None      None.1 Thousands Uganda Shillings  \\\n",
      "0  External Fin.       Total                        NaN   \n",
      "1           None        None                        NaN   \n",
      "2              0     958,851                        NaN   \n",
      "3      9,661,277  93,633,124                        NaN   \n",
      "4              0   2,005,244                        NaN   \n",
      "\n",
      "  Total Excluding Arrears 266,506,287 189,107,094 455,613,382  \\\n",
      "0                     NaN         NaN         NaN         NaN   \n",
      "1                     NaN         NaN         NaN         NaN   \n",
      "2                     NaN         NaN         NaN         NaN   \n",
      "3                     NaN         NaN         NaN         NaN   \n",
      "4                     NaN         NaN         NaN         NaN   \n",
      "\n",
      "  Million Uganda Shillings  \n",
      "0                      NaN  \n",
      "1                      NaN  \n",
      "2                      NaN  \n",
      "3                      NaN  \n",
      "4                      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# Function to rename duplicate columns safely\n",
    "def deduplicate_columns(cols):\n",
    "    seen = {}\n",
    "    new_cols = []\n",
    "    for col in cols:\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_cols.append(f\"{col}.{seen[col]}\")\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "            new_cols.append(col)\n",
    "    return new_cols\n",
    "\n",
    "# Extract tables from the already-loaded PDF file\n",
    "all_tables = []\n",
    "\n",
    "with pdfplumber.open(pdf_file) as pdf:\n",
    "    for page_num, page in enumerate(pdf.pages):\n",
    "        tables = page.extract_tables()\n",
    "        for table_num, table in enumerate(tables):\n",
    "            if table:\n",
    "                try:\n",
    "                    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "\n",
    "                    if not df.columns.is_unique:\n",
    "                        df.columns = deduplicate_columns(df.columns)\n",
    "                        print(f\"🔄 Renamed duplicate columns on page {page_num+1}, table {table_num+1}\")\n",
    "                    \n",
    "                    all_tables.append(df)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error processing table on page {page_num+1}, table {table_num+1}: {e}\")\n",
    "\n",
    "# Combine all tables\n",
    "if all_tables:\n",
    "    combined_df = pd.concat(all_tables, ignore_index=True)\n",
    "    print(\"✅ Combined DataFrame preview:\")\n",
    "    print(combined_df.head())\n",
    "else:\n",
    "    print(\"❌ No usable tables found in the PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96399a3a-ff7d-4a23-9f92-20ea4fa3acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"education_vote013_extracted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc003a5-0f5c-443b-b094-def9f68f17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"education_vote013_extracted.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe07422-b97b-4469-88e4-e952af1a176e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Actual'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Actual'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerformance (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApproved\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeviation (UGX)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApproved\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution Status\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerformance (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFully Spent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m95\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderutilized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Actual'"
     ]
    }
   ],
   "source": [
    "df[\"Performance (%)\"] = (df[\"Actual\"] / df[\"Approved\"]) * 100\n",
    "df[\"Deviation (UGX)\"] = df[\"Approved\"] - df[\"Actual\"]\n",
    "df[\"Execution Status\"] = df[\"Performance (%)\"].apply(lambda x: \"Fully Spent\" if x >= 95 else \"Underutilized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca6eb6-9bcb-4a60-aeb7-a01e8af9ee0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
